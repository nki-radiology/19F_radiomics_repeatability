{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95081d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T16:35:38.594307Z",
     "start_time": "2025-07-17T16:35:30.934896Z"
    }
   },
   "outputs": [],
   "source": [
    "#Summary stats of features\n",
    "import pandas as pd\n",
    "from scipy.stats import wilcoxon\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "file_path = r\"\\PATH.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "columns_of_interest = [\n",
    "    \"Feature\",\n",
    "    \"PFPE intrasession CCC\",\n",
    "    \"PFPE intersession CCC\",\n",
    "    \"PFCE intrasession CCC\",\n",
    "    \"PFCE intersession CCC\", \n",
    "    \"In vivo intrasession CCC\"\n",
    "]\n",
    "df_filtered = df[columns_of_interest]\n",
    "\n",
    "shape_keywords = ['shape']\n",
    "intensity_keywords = ['firstorder']\n",
    "texture_keywords = [kw for kw in df_filtered[\"Feature\"] if kw not in shape_keywords + intensity_keywords]\n",
    "\n",
    "def calculate_median_iqr(df_column):\n",
    "    median = df_column.median()\n",
    "    q25 = df_column.quantile(0.25)\n",
    "    q75 = df_column.quantile(0.75)\n",
    "    return median, q25, q75\n",
    "\n",
    "shape_features = df_filtered[df_filtered['Feature'].str.contains('|'.join(shape_keywords), case=False)]\n",
    "intensity_features = df_filtered[df_filtered['Feature'].str.contains('|'.join(intensity_keywords), case=False)]\n",
    "texture_features = df_filtered[~df_filtered['Feature'].str.contains('|'.join(shape_keywords + intensity_keywords), case=False)]\n",
    "\n",
    "summary_stats = {}\n",
    "for col in columns_of_interest[1:]:\n",
    "    overall_median, overall_q25, overall_q75 = calculate_median_iqr(df_filtered[col])\n",
    "    shape_median, shape_q25, shape_q75 = calculate_median_iqr(shape_features[col])\n",
    "    intensity_median, intensity_q25, intensity_q75 = calculate_median_iqr(intensity_features[col])\n",
    "    texture_median, texture_q25, texture_q75 = calculate_median_iqr(texture_features[col])\n",
    "\n",
    "    summary_stats[col] = {\n",
    "        \"Overall CCC Median (IQR)\": f\"{overall_median:.3f} ({overall_q25:.3f} - {overall_q75:.3f})\",\n",
    "        \"Shape CCC Median (IQR)\": f\"{shape_median:.3f} ({shape_q25:.3f} - {shape_q75:.3f})\",\n",
    "        \"Intensity CCC Median (IQR)\": f\"{intensity_median:.3f} ({intensity_q25:.3f} - {intensity_q75:.3f})\",\n",
    "        \"Texture CCC Median (IQR)\": f\"{texture_median:.3f} ({texture_q25:.3f} - {texture_q75:.3f})\"\n",
    "    }\n",
    "\n",
    "summary_stats_df = pd.DataFrame(summary_stats).T\n",
    "summary_stats_df#.to_excel('general_ccc_stats.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbe82cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T16:35:41.184056Z",
     "start_time": "2025-07-17T16:35:41.148934Z"
    }
   },
   "outputs": [],
   "source": [
    "#Statistical testing of the distribution of CCCs across features\n",
    "from scipy.stats import kruskal\n",
    "\n",
    "test_results = []\n",
    "for col in columns_of_interest[1:]:\n",
    "    overall = df_filtered[col].dropna()\n",
    "    shape = shape_features[col].dropna()\n",
    "    intensity = intensity_features[col].dropna()\n",
    "    texture = texture_features[col].dropna()\n",
    "\n",
    "    # Kruskal-Wallis\n",
    "    if len(overall) > 0 and len(shape) > 0:\n",
    "        _, p_shape = kruskal(overall, shape)\n",
    "        test_results.append({'Comparison': f'{col}: Overall vs Shape', 'P-value': p_shape})\n",
    "    if len(overall) > 0 and len(intensity) > 0:\n",
    "        _, p_intensity = kruskal(overall, intensity)\n",
    "        test_results.append({'Comparison': f'{col}: Overall vs Intensity', 'P-value': p_intensity})\n",
    "    if len(overall) > 0 and len(texture) > 0:\n",
    "        _, p_texture = kruskal(overall, texture)\n",
    "        test_results.append({'Comparison': f'{col}: Overall vs Texture', 'P-value': p_texture})\n",
    "\n",
    "# Correct for multiple testing \n",
    "p_values = [result['P-value'] for result in test_results]\n",
    "corrections = multipletests(p_values, method='fdr_bh')\n",
    "for i, result in enumerate(test_results):\n",
    "    result['Adjusted P-value'] = corrections[1][i]\n",
    "\n",
    "test_results_df = pd.DataFrame(test_results)\n",
    "\n",
    "test_results_df#.to_excel('comparison_overall_stratified.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efafa0f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T16:37:59.974763Z",
     "start_time": "2025-07-17T16:37:59.914243Z"
    }
   },
   "outputs": [],
   "source": [
    "# Testing for normality of CCC values\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "normality_results = []\n",
    "\n",
    "for col in columns_of_interest[1:]:\n",
    "    # Full dataset\n",
    "    stat_all, p_all = shapiro(df_filtered[col].dropna())\n",
    "    normality_results.append({\n",
    "        'CCC Type': col,\n",
    "        'Group': 'All',\n",
    "        'Shapiro-W': stat_all,\n",
    "        'P-value': p_all\n",
    "    })\n",
    "\n",
    "    # Shape features\n",
    "    stat_shape, p_shape = shapiro(shape_features[col].dropna())\n",
    "    normality_results.append({\n",
    "        'CCC Type': col,\n",
    "        'Group': 'Shape',\n",
    "        'Shapiro-W': stat_shape,\n",
    "        'P-value': p_shape\n",
    "    })\n",
    "\n",
    "    # Intensity features\n",
    "    stat_intensity, p_intensity = shapiro(intensity_features[col].dropna())\n",
    "    normality_results.append({\n",
    "        'CCC Type': col,\n",
    "        'Group': 'Intensity',\n",
    "        'Shapiro-W': stat_intensity,\n",
    "        'P-value': p_intensity\n",
    "    })\n",
    "\n",
    "    # Texture features\n",
    "    stat_texture, p_texture = shapiro(texture_features[col].dropna())\n",
    "    normality_results.append({\n",
    "        'CCC Type': col,\n",
    "        'Group': 'Texture',\n",
    "        'Shapiro-W': stat_texture,\n",
    "        'P-value': p_texture\n",
    "    })\n",
    "\n",
    "normality_df = pd.DataFrame(normality_results)\n",
    "normality_df\n",
    "\n",
    "# non_normal_distributions = normality_df[normality_df['P-value'] < 0.05]\n",
    "\n",
    "normality_df#.to_excel('normality_testing.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f5ff17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T16:12:50.391970Z",
     "start_time": "2025-01-10T16:12:50.365539Z"
    }
   },
   "outputs": [],
   "source": [
    "comparison_results = []\n",
    "for prefix, intra_col, inter_col in [\n",
    "    (\"PFPE\", \"PFPE intrasession CCC\", \"PFPE intersession CCC\"),\n",
    "    (\"PFCE\", \"PFCE intrasession CCC\", \"PFCE intersession CCC\")\n",
    "]:\n",
    "    # Overall comparison\n",
    "    intra_overall = df_filtered[intra_col].dropna()\n",
    "    inter_overall = df_filtered[inter_col].dropna()\n",
    "    if len(intra_overall) > 0 and len(inter_overall) > 0:\n",
    "        _, p_overall = kruskal(intra_overall, inter_overall)\n",
    "        comparison_results.append({\n",
    "            \"Comparison\": f\"{prefix} Overall Intrasession vs Intersession\",\n",
    "            \"P-value\": p_overall\n",
    "        })\n",
    "    \n",
    "    # Stratified comparisons\n",
    "    for category, features in zip(\n",
    "        [\"Shape\", \"Intensity\", \"Texture\"],\n",
    "        [shape_features, intensity_features, texture_features]\n",
    "    ):\n",
    "        intra_category = features[intra_col].dropna()\n",
    "        inter_category = features[inter_col].dropna()\n",
    "        if len(intra_category) > 0 and len(inter_category) > 0:\n",
    "            _, p_category = kruskal(intra_category, inter_category)\n",
    "            comparison_results.append({\n",
    "                \"Comparison\": f\"{prefix} {category} Intrasession vs Intersession\",\n",
    "                \"P-value\": p_category\n",
    "            })\n",
    "\n",
    "# Correct for multiple testing\n",
    "p_values = [result['P-value'] for result in comparison_results]\n",
    "corrections = multipletests(p_values, method='fdr_bh')\n",
    "for i, result in enumerate(comparison_results):\n",
    "    result['Adjusted P-value'] = corrections[1][i]\n",
    "\n",
    "comparison_results_df = pd.DataFrame(comparison_results)\n",
    "\n",
    "comparison_results_df#.to_excel('comparison_intra_vs_interssion.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75824b11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T16:16:56.625094Z",
     "start_time": "2025-01-10T16:16:56.600575Z"
    }
   },
   "outputs": [],
   "source": [
    "# Perform comparisons of PFPE vs PFCE for intrasession and intersession CCC\n",
    "pfpe_vs_pfce_results = []\n",
    "for session_type, pfpe_col, pfce_col in [\n",
    "    (\"Intrasession\", \"PFPE intrasession CCC\", \"PFCE intrasession CCC\"),\n",
    "    (\"Intersession\", \"PFPE intersession CCC\", \"PFCE intersession CCC\"),\n",
    "]:\n",
    "    # Overall comparison\n",
    "    pfpe_overall = df_filtered[pfpe_col].dropna()\n",
    "    pfce_overall = df_filtered[pfce_col].dropna()\n",
    "    if len(pfpe_overall) > 0 and len(pfce_overall) > 0:\n",
    "        _, p_overall = kruskal(pfpe_overall, pfce_overall)\n",
    "        pfpe_vs_pfce_results.append({\n",
    "            \"Comparison\": f\"Overall {session_type}: PFPE vs PFCE\",\n",
    "            \"P-value\": p_overall\n",
    "        })\n",
    "\n",
    "    # Stratified comparisons\n",
    "    for category, features in zip(\n",
    "        [\"Shape\", \"Intensity\", \"Texture\"],\n",
    "        [shape_features, intensity_features, texture_features]\n",
    "    ):\n",
    "        pfpe_category = features[pfpe_col].dropna()\n",
    "        pfce_category = features[pfce_col].dropna()\n",
    "        if len(pfpe_category) > 0 and len(pfce_category) > 0:\n",
    "            _, p_category = kruskal(pfpe_category, pfce_category)\n",
    "            pfpe_vs_pfce_results.append({\n",
    "                \"Comparison\": f\"{category} {session_type}: PFPE vs PFCE\",\n",
    "                \"P-value\": p_category\n",
    "            })\n",
    "\n",
    "# Correct for multiple testing\n",
    "p_values = [result['P-value'] for result in pfpe_vs_pfce_results]\n",
    "corrections = multipletests(p_values, method='fdr_bh')\n",
    "for i, result in enumerate(pfpe_vs_pfce_results):\n",
    "    result['Adjusted P-value'] = corrections[1][i]\n",
    "\n",
    "pfpe_vs_pfce_results_df = pd.DataFrame(pfpe_vs_pfce_results)\n",
    "\n",
    "pfpe_vs_pfce_results_df#.to_excel('comparison_pfpe_vs_pfce.xlsx')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
